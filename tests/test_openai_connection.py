#!/usr/bin/env python3
"""
Test script to verify OpenAI API connection is working.
"""

import os
import sys
from openai import OpenAI

def test_openai_connection():
    """Test if OpenAI API is accessible and responding."""
    
    # Get configuration from environment
    api_key = os.environ.get("OPENAI_API_KEY")
    backend_url = os.environ.get("LLM_BACKEND_URL", "https://api.openai.com/v1")
    provider = os.environ.get("LLM_PROVIDER", "openai")
    
    print(f"Testing OpenAI API connection:")
    print(f"  Provider: {provider}")
    print(f"  Backend URL: {backend_url}")
    print(f"  API Key: {'‚úÖ Set' if api_key and api_key != '<your-openai-key>' else '‚ùå Not set or using placeholder'}")
    
    if not api_key or api_key == "<your-openai-key>":
        print("‚ùå OPENAI_API_KEY is not set or still using placeholder value")
        print("   Please set your OpenAI API key in the .env file")
        return False
    
    # Test 1: Initialize OpenAI client
    try:
        client = OpenAI(
            api_key=api_key,
            base_url=backend_url
        )
        print("‚úÖ OpenAI client initialized successfully")
    except Exception as e:
        print(f"‚ùå Failed to initialize OpenAI client: {e}")
        return False
    
    # Test 2: Test chat completion with a simple query
    try:
        print("üß™ Testing chat completion...")
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Use the most cost-effective model for testing
            messages=[
                {"role": "user", "content": "Hello! Please respond with exactly: 'OpenAI API test successful'"}
            ],
            max_tokens=50,
            temperature=0
        )
        
        if response.choices and response.choices[0].message.content:
            content = response.choices[0].message.content.strip()
            print(f"‚úÖ Chat completion successful")
            print(f"   Model: {response.model}")
            print(f"   Response: {content}")
            print(f"   Tokens used: {response.usage.total_tokens if response.usage else 'unknown'}")
        else:
            print("‚ùå Chat completion returned empty response")
            return False
            
    except Exception as e:
        print(f"‚ùå Chat completion test failed: {e}")
        if "insufficient_quota" in str(e).lower():
            print("   üí° This might be a quota/billing issue. Check your OpenAI account.")
        elif "invalid_api_key" in str(e).lower():
            print("   üí° Invalid API key. Please check your OPENAI_API_KEY.")
        return False
    
    # Test 3: Test embeddings (optional, for completeness)
    try:
        print("üß™ Testing embeddings...")
        response = client.embeddings.create(
            model="text-embedding-3-small",  # Cost-effective embedding model
            input="This is a test sentence for embeddings."
        )
        
        if response.data and len(response.data) > 0 and response.data[0].embedding:
            embedding = response.data[0].embedding
            print(f"‚úÖ Embeddings successful")
            print(f"   Model: {response.model}")
            print(f"   Embedding dimension: {len(embedding)}")
            print(f"   Tokens used: {response.usage.total_tokens if response.usage else 'unknown'}")
        else:
            print("‚ùå Embeddings returned empty response")
            return False
            
    except Exception as e:
        print(f"‚ùå Embeddings test failed: {e}")
        print("   ‚ö†Ô∏è Embeddings test failed but chat completion worked. This is usually fine for basic usage.")
        # Don't return False here as embeddings might not be critical for all use cases
    
    return True

def test_config_validation():
    """Validate the configuration is properly set for OpenAI."""
    
    provider = os.environ.get("LLM_PROVIDER", "").lower()
    backend_url = os.environ.get("LLM_BACKEND_URL", "")
    
    print("\nüîß Configuration validation:")
    
    if provider != "openai":
        print(f"‚ö†Ô∏è LLM_PROVIDER is '{provider}', expected 'openai'")
        print("   The app might still work if the provider supports OpenAI-compatible API")
    else:
        print("‚úÖ LLM_PROVIDER correctly set to 'openai'")
    
    if "openai.com" in backend_url:
        print("‚úÖ Using official OpenAI API endpoint")
    elif backend_url:
        print(f"‚ÑπÔ∏è Using custom endpoint: {backend_url}")
        print("   Make sure this endpoint is OpenAI-compatible")
    else:
        print("‚ö†Ô∏è LLM_BACKEND_URL not set, using default")
    
    # Check for common environment issues
    finnhub_key = os.environ.get("FINNHUB_API_KEY")
    if not finnhub_key or finnhub_key == "<your_finnhub_api_key_here>":
        print("‚ö†Ô∏è FINNHUB_API_KEY not set - financial data fetching may not work")
    else:
        print("‚úÖ FINNHUB_API_KEY is set")
    
    return True

if __name__ == "__main__":
    print("üß™ OpenAI API Connection Test\n")
    
    config_ok = test_config_validation()
    api_ok = test_openai_connection()
    
    print(f"\nüìä Test Results:")
    print(f"   Configuration: {'‚úÖ OK' if config_ok else '‚ùå Issues'}")
    print(f"   API Connection: {'‚úÖ OK' if api_ok else '‚ùå Failed'}")
    
    if config_ok and api_ok:
        print("\nüéâ All tests passed! OpenAI API is ready for TradingAgents.")
        print("üí° You can now run the trading agents with OpenAI as the LLM provider.")
    else:
        print("\nüí• Some tests failed. Please check your configuration and API key.")
        print("üí° Make sure OPENAI_API_KEY is set correctly in your .env file.")
    
    sys.exit(0 if (config_ok and api_ok) else 1)